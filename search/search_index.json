{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Introduction","text":"<p>There is currently no centralised, unbiased, user-centred approach to providing comprehensive help for young people to explore and navigate their options (e.g. post-GCSE options, especially technical and apprenticeships).</p> <p>There is an opportunity to create a single service that:</p> <ul> <li>empowers young people to FIND and explore all their education and training options</li> <li>helps those facing additional barriers</li> <li>assists parents, teachers and careers advisors to support these decisions</li> </ul> <p>It improves on existing search tools, by:</p> <ul> <li>Bringing together all government funded education and training opportunities into a single, unified search.</li> <li>Making it easier for users to find what they are looking for, especially when they don\u2019t know what an education or training opportunity is called.</li> </ul>"},{"location":"#documentation","title":"Documentation","text":"<p>This site is a collection of documentation to help developers understand the project and its components.</p>"},{"location":"architecture/application-architecture/","title":"Application Architecture","text":""},{"location":"architecture/application-architecture/#c4-system-landscape","title":"C4: System Landscape","text":""},{"location":"architecture/application-architecture/#component-summary","title":"Component Summary","text":"Component SLA Azure App Service 99.95% Azure Front Door 99.95% Azure Redis Cache 99.99% Azure SQL Server 99.99% Microsoft AI Search 99.95% Azure OpenAI Service 99.99% <p>Basion is not included as this is not required for day to day running and is only required for developer access at intermittent times</p>"},{"location":"architecture/application-architecture/#availability","title":"Availability","text":"<p>The table shows the composite availability. All Services is for when the entire system is running.</p> Scenario Availability All Services 99.97%"},{"location":"architecture/deployment-architecture/","title":"Deployment Architecture","text":"<p>The build and release pipelines are all controlled via GitHub actions which act as our CI/CD process.</p> <p>The actions are categorised into different types: - Validate: Perform some sort of validation, such as running tests and are typically pass/fail - Generate: Generate some sort of artifact, such as reporting - Deploy: Perform a deployment to a target environment</p>"},{"location":"architecture/deployment-architecture/#build-pipeline","title":"Build Pipeline","text":"<p>On creation of a Pull Request or push to main, multiple validation actions run, depending on what areas of the repo have been modified. Any failures should be addressed before merging. Failures on main should be fixed as priority.</p>"},{"location":"architecture/deployment-architecture/#release-pipeline","title":"Release Pipeline","text":"<p>TODO</p>"},{"location":"architecture/front-door/","title":"Azure Front Door","text":"<p>To protect the site from intrusion and general threats, as well as handling things like SSL certificates, we are using Front Door combined with the Web Application Firewall.</p>"},{"location":"architecture/front-door/#threat-blocking","title":"Threat Blocking","text":""},{"location":"architecture/front-door/#front-door-premium","title":"Front Door Premium","text":"<p>Azure Front Door Premium is utilised to handle threat blocking, bot detection, and ensure the site mitigates the latest OWASP threats with as little intervention as possible.</p>"},{"location":"architecture/terraform/","title":"Terraform","text":""},{"location":"architecture/terraform/#requirements","title":"Requirements","text":"Name Version terraform &gt;= 1.13.4 azapi 2.2.0 azurerm ~&gt; 4.50"},{"location":"architecture/terraform/#providers","title":"Providers","text":"Name Version azapi 2.2.0 azurerm ~&gt; 4.50"},{"location":"architecture/terraform/#modules","title":"Modules","text":"<p>No modules.</p>"},{"location":"architecture/terraform/#resources","title":"Resources","text":"Name Type azapi_resource.feat_main_subnet resource azurerm_app_service_virtual_network_swift_connection.api_app_vn_conn resource azurerm_app_service_virtual_network_swift_connection.website_app_vn_conn resource azurerm_container_registry.feat-registry resource azurerm_linux_web_app.feat-api resource azurerm_linux_web_app.feat-website resource azurerm_managed_redis.feat_redis_enterprise resource azurerm_mssql_database.feat_mssql_db resource azurerm_mssql_server.feat_mssql_server resource azurerm_mssql_virtual_network_rule.mssql_vnet_rule resource azurerm_network_security_group.feat-nsg resource azurerm_private_dns_zone.default resource azurerm_private_dns_zone_virtual_network_link.default resource azurerm_resource_group.feat-rg resource azurerm_search_service.feat_search_service resource azurerm_service_plan.feat-ing-asp resource azurerm_service_plan.feat-web-asp resource azurerm_storage_account.feat_storage_account resource azurerm_storage_container.feat_storage_container resource azurerm_virtual_network.feat_vnet resource"},{"location":"architecture/terraform/#inputs","title":"Inputs","text":"Name Description Type Default Required api_image_name The repository name and tag for the API container. <code>string</code> n/a yes env Environment (dev, test, prod) <code>string</code> n/a yes location Azure region <code>string</code> <code>\"uksouth\"</code> no partition_count Partitions allow for scaling of document count as well as faster indexing by sharding your index over multiple search units. <code>number</code> <code>1</code> no prefix Prefix for resource names <code>string</code> <code>\"s265\"</code> no product Name of the project <code>string</code> <code>\"Find Education and Training\"</code> no replica_count Replicas distribute search workloads across the service. You need at least two replicas to support high availability of query workloads (not applicable to the free tier). <code>number</code> <code>1</code> no sku The pricing tier of the search service you want to create (for example, basic or standard). <code>string</code> <code>\"standard\"</code> no sql_admin_password The administrator password of the SQL logical server. <code>string</code> <code>null</code> no sql_admin_username The administrator username of the SQL logical server. <code>string</code> <code>\"azureadmin\"</code> no website_image_name The repository name and tag for the website container. <code>string</code> n/a yes"},{"location":"architecture/terraform/#outputs","title":"Outputs","text":"Name Description api_url n/a azurerm_network_security_group Network security group name azurerm_private_dns_zone Private DNS Zone name azurerm_private_dns_zone_virtual_network_link Private DNS Zone Virtual Network Link name azurerm_subnet Subnet name azurerm_virtual_network Virtual network name mssql_database_name The name of the SQL Database mssql_server_fqdn The fully qualified domain name of the SQL Server mssql_server_name The name of the SQL Server search_service_name The name of the Azure Search Service website_url n/a"},{"location":"architecture/volumetrics/","title":"Volumetrics","text":""},{"location":"architecture/volumetrics/#introduction","title":"Introduction","text":"<p>It is important to understand the Volumetrics of the Find Education and Training site to ensure that the website can handle the expected traffic without degradation in performance, without incurring unnecessary Azure costs.</p> <p>This is a new site, so no historical data is available. However, we can make estimates based on data from other similar sites such as the Find A Course and Find an Apprenticeship.</p>"},{"location":"architecture/volumetrics/#projected-volumetrics","title":"Projected Volumetrics","text":"<p>The assumptions will be based on xxx users per month.</p> <p>We can make reasonable assumptions that the site will be operating during UK day time hours, with increased usage around exam results times in August and January.  Therefore, we can make an assumption of around yy users per hour at peak times.</p> <p>Assuming a user session lasts roughly xx minutes: xx * yy = zz concurrent requests.</p> <p>TODO: Sort volumetrics</p> Test Type Concurrent Users Requests per second Normal xx ~x requests/sec Spike yy ~y requests/sec Stress zzz ~zz requests/sec"},{"location":"architecture/adr/001-external-entry-point/","title":"Decision - 001 - External Entry Point","text":""},{"location":"architecture/adr/001-external-entry-point/#context-and-problem-statement","title":"Context and Problem Statement","text":"<p>The site needs to ensure it is protected against threats on the internet, but that it is also performant and scalable.</p> <p>We needed to ensure:</p> <ul> <li>Infrastructure costs are as low as possible</li> <li>Infrastructure is simple and easy to manage</li> <li>The site must support custom DfE subdomains and SSL</li> <li>The site can be scaled out and load balanced accordingly</li> </ul>"},{"location":"architecture/adr/001-external-entry-point/#considered-options","title":"Considered Options","text":"<ul> <li>Azure Front Door</li> <li>Azure Application Gateway</li> <li>Shared DfE Baracuda WAF</li> </ul>"},{"location":"architecture/adr/001-external-entry-point/#evaluation","title":"Evaluation","text":"Criteria Comment Front Door Application Gateway Baracuda WAF Cost Front Door Premium is approximately 330 USD per month, Front Door Standard is 35 USD per month, and Application Gateway has a wide range of costs, but usually starting at around 330 USD per month, the Baracuda WAF is already managed by DfE and so incurs no extra cost 4 3 5 Performance Performance is on-par across the three solutions 4 4 4 Security Front Door Premium supports additional managed rules, allowing for restrictions to be bypassed for friendly search engine bots. It also supports managed rulesets which adhere to WASP security guidelines. Application Gateway can do this, but at additional cost and usually involving a combination of Application Gateway and Front Door. The Baracuda WAF is already managed by DfE and should already be designed to adhere to the current WASP security guidelines. 4 2 4 Maintenance Front Door allows for custom domains and SSL certificate generation. Application Gateway requires SSL certificates to be deployed and managed separately, increasing maintenance costs and effort, plus the risk of missing a renewal. There are already processes in place to support handling domain renewals etc for the Baracuda firewall within DfE 4 1 5 Total 16 10 18"},{"location":"architecture/adr/001-external-entry-point/#decision-outcome","title":"Decision Outcome","text":"<p>Based on the analysis above, we have chosen the DfE Baracuda WAF to protect the site.</p>"},{"location":"architecture/adr/001-external-entry-point/#considerations-on-selected-technology","title":"Considerations on selected technology","text":"<p>Pros and cons had been taken to the DfE Architectural Group monthly meetings and, while Application Gateway does have some features that give it a bonus over Front Door, none of those features are being used within this service.</p> <p>In this situation, however, as we have no custom rules that need defining, the Baracuda WAF will work sufficiently for us.</p>"},{"location":"architecture/adr/002-relational-database/","title":"Decision - 002 - Relational Database","text":""},{"location":"architecture/adr/002-relational-database/#context-and-problem-statement","title":"Context and Problem Statement","text":"<p>The site needs a relational database to store rich information about courses and vacancies, but the information does not need to be used as criteria within a search.</p> <p>We needed to ensure:</p> <ul> <li>Infrastructure costs are as low as possible</li> <li>Infrastructure is simple and easy to manage</li> <li>We follow DfE best practices</li> <li>The relational database chosen can be supported by the current, and future teams</li> </ul>"},{"location":"architecture/adr/002-relational-database/#considered-options","title":"Considered Options","text":"<ul> <li>Microsoft SQL Server 2022</li> <li>Microsoft SQL Server 2025 Preview</li> <li>Azure Flexible PostgreSQL</li> </ul>"},{"location":"architecture/adr/002-relational-database/#evaluation","title":"Evaluation","text":"Criteria Comment MSSQL 2022 MSSQL 2025 PostgreSQL Cost SQL Server costs more than PostgreSQL due to the additional licensing costs, however we may be able to make some mitigations on the deployment model to help reduce the costs 3 3 4 Performance Performance is on-par across the two solutions 4 4 4 Features SQL 2025 has additional features to support vectors and functionality that AI might be able to leverage, but these features are still in preview mode and not generally available, therefore these shouldn't be considered for a production-ready system yet - this may change after Microsoft Ignite 2025 4 3 3 Maintenance After speaking with Luke Slowen, Richard Boland, and the potential future owners of the service, it has been deemed that DfE would be better suited to attempting to standardise which relational database to use department-wide. The database of choice is Microsoft SQL Server, which means that PostgreSQL should be the exception, not the rule. 4 4 1 Total 15 14 12"},{"location":"architecture/adr/002-relational-database/#decision-outcome","title":"Decision Outcome","text":"<p>Based on the analysis above, we have chosen Microsoft SQL Server 2022 to be the relational database for the site.</p>"},{"location":"architecture/adr/002-relational-database/#considerations-on-selected-technology","title":"Considerations on selected technology","text":"<p>Pros and cons had been taken to the DfE Architectural Group, along with discussions with Microsoft directly as part of our Tech Team times, however the new features that might become available haven't get moved into General Availability, which is why SQL 2022 has been chosen over SQL 2025 Preview</p>"},{"location":"architecture/adr/003-caching/","title":"Decision - 003 - Caching","text":""},{"location":"architecture/adr/003-caching/#context-and-problem-statement","title":"Context and Problem Statement","text":"<p>The site needs to be performant and cost-efficient when undertaking the following:</p> <ul> <li>Scaling-out to support spikes in demand</li> <li>Cost-efficient when handling things such as text embedding</li> </ul> <p>We needed to ensure:</p> <ul> <li>Infrastructure costs are as low as possible</li> <li>Infrastructure is simple and easy to manage</li> <li>We follow DfE best practices</li> <li>If the site scales, any caching and evictions apply to all scaled instances</li> </ul>"},{"location":"architecture/adr/003-caching/#considered-options","title":"Considered Options","text":"<ul> <li>No Caching</li> <li>In-Memory Caching</li> <li>FusionCache with an Azure Cache for Redis Backplane</li> <li>Microsoft Hybrid Cache with an Azure Cache for Redis Distributed Cache</li> <li>Microsoft Hybrid Cache with a Microsoft SQL Server Distributed Cache</li> </ul>"},{"location":"architecture/adr/003-caching/#evaluation","title":"Evaluation","text":"Criteria Comment No Caching In-Memory FusionCache Hybrid/Redis Hybrid/SQL Adoption The implementation should we widely used and have excellent documentation 1 4 4 4 4 Development Cost The implementation should not require any additional development cost, tooling, or understanding of the backing cache 1 3 4 4 4 Performance The caching should work with as little latency as possible across various environments 1 3 4 4 4 Scaling The caching should survive an application restart, deployment, or scaling automatically 1 1 4 4 4 Clearing Cache The caching should allow quick and easy clearing, plus support additional things like tagging for easier related content removal, plus clearing the cache on one node of a load balanced system MUST clear the cache on all other nodes 1 2 5 2 2 Deployment Cost The caching should use existing technologies where available which wouldn't incur additional costs 5 5 3 3 4 Total 10 20 24 21 22"},{"location":"architecture/adr/003-caching/#decision-outcome","title":"Decision Outcome","text":"<p>Based on the analysis above, we have chose to use FusionCache as this has great documentation and was, in fact, ahead of Microsoft in making itself HybridCache compatible.</p> <p>FusionCache allows us to support the following features:</p> <ul> <li>L1 cache in-memory</li> <li>L2 cache using IDistributedCache (in this case, Redis)</li> <li>Ability to use the Redis instance as a backplane to enable communication between nodes</li> <li>Tagging support</li> <li>Clearing the cache using the * tag</li> </ul> <p>While HybridCache is now in mainstream support, it still does not support using the L2 layer as a backplane and notifying other nodes that the cache has been cleared, therefore leaving stale in-memory cache entries in all other nodes.</p>"},{"location":"architecture/adr/003-caching/#considerations-on-selected-technology","title":"Considerations on selected technology","text":"<p>During development, the cache can be deployed using L1 cache only, which allows application restarts to flush the cache, but still allow for testing of caching.</p>"},{"location":"architecture/adr/004-replace-azure-cache-for-redis/","title":"Decision - 004 - Replacing Azure Cache for Redis","text":""},{"location":"architecture/adr/004-replace-azure-cache-for-redis/#context-and-problem-statement","title":"Context and Problem Statement","text":"<p>Azure Cache for Redis is being retured on September 30th 2028, as specified in the Azure Cache for Redis Retirement FAQ</p> <ul> <li>Creation of new instances will be blocked from April 1st 2026</li> <li>Existing customers will be blocked from creating instances from October 1st 2026</li> <li>Instances will be disabled from October 1st 2028</li> </ul>"},{"location":"architecture/adr/004-replace-azure-cache-for-redis/#considered-options","title":"Considered Options","text":"<ul> <li>Do nothing</li> <li>Put in a migration plan for 2026</li> <li>Upgrade now</li> </ul>"},{"location":"architecture/adr/004-replace-azure-cache-for-redis/#decision-outcome","title":"Decision Outcome","text":"<p>To avoid having to redeploy and migrate at a later date, we have taken the decision to move straight to Azure Managed Redis.</p> <p>As we were due to use a relatively lightweight cache with a fairly low overhead, we will be able to stay with the lower-tiered Balanced instances, therefore keeping costs low.</p> <p>In order to make these instances as cost effective as possible, it is deemed that we will be use the following:</p> <ul> <li>Development: B0 One-Node (Non-High Availability)</li> <li>Staging: B0 Two-Node (High Availability)</li> <li>Production: B1 Two-Node (High Availability)</li> </ul> <p>If monitoring shows that the cache is getting filled quickly, we can look to scale up to B3 or B5 to increase the memory headroom.</p>"},{"location":"developers/branching-strategy/","title":"Branching strategy and code quality","text":""},{"location":"developers/branching-strategy/#branching-strategy","title":"Branching strategy","text":"<p>This project uses the Trunk Based Development branching strategy. This strategy seeks to avoid long-running feature/release branches and all work is based on <code>main</code>.</p> <p>Small tweaks and chore work can be done directly on <code>main</code> but more complex features including logic should be done in a feature branch and merged back into <code>main</code> via a pull request.</p> <p>Long-running feature branches that drift too far from <code>main</code> should be avoided to avoid merge conflicts.</p> <p>Feature branches should be squashed and rebased onto main before being fast-forwarded into main. This ensures an easy-to-follow git history and avoids merge commits.</p>"},{"location":"developers/branching-strategy/#code-quality-and-rules","title":"Code quality and rules","text":"<p>Before pushing to main/raising a pull request, ensure the following: - The build is passing and any relevant tests are passing. - The code is formatted correctly. - Errant comments and debug code are removed.</p> <p>The following checks/actions run on every pull request or main push:</p> <p>TODO: Define these</p>"},{"location":"developers/definition-of-done/","title":"Definition of Done","text":""},{"location":"developers/definition-of-done/#purpose","title":"Purpose","text":"<p>The Definition of Done ensures that all work delivered by the team meets a consistent quality standard and is production-ready. A user story, task, or bug fix is only considered Done when it meets all the criteria below.</p>"},{"location":"developers/definition-of-done/#general-criteria","title":"General Criteria","text":"<ul> <li>[ ] Code is peer reviewed (via pull request) and approved  </li> <li>[ ] Code is merged into main branch (via pull request) without conflicts  </li> <li>[ ] Code follows agreed coding standards and style guidelines  </li> <li>[ ] All acceptance criteria from the user story or task are met  </li> <li>[ ] No known critical or high-severity defects remain open  </li> <li>[ ] Jira user story linked to an Epic  </li> <li>[ ] Branch naming follows agreed conventions  </li> <li>[ ] Commit messages follow agreed conventions  </li> <li>[ ] Meets agreed non-functional requirements (NFRs) for performance, scalability, and reliability  </li> <li>[ ] Accessibility considerations addressed from design through to implementation  </li> </ul>"},{"location":"developers/definition-of-done/#testing-quality","title":"Testing &amp; Quality","text":"<ul> <li>[ ] Unit tests are written and passing  </li> <li>[ ] Integration and/or end-to-end tests updated where necessary  </li> <li>[ ] All automated tests in the CI/CD pipeline pass  </li> <li>[ ] Manual exploratory testing completed for edge cases and usability  </li> <li>[ ] All linked defects resolved or triaged with agreed mitigations  </li> <li>[ ] Evidence provided in test reports or dashboards  </li> <li>[ ] Accessibility testing completed (WCAG 2.2 AA compliance)  </li> <li>[ ] Cross-browser/device testing completed where relevant  </li> </ul>"},{"location":"developers/definition-of-done/#documentation","title":"Documentation","text":"<ul> <li>[ ] Code is commented where necessary for clarity  </li> <li>[ ] API contracts, schemas, and models are updated  </li> <li>[ ] User-facing documentation updated if relevant</li> <li>[ ] Knowledge shared with the team (eg. Confluence, show &amp; tell)  </li> <li>[ ] Testing evidence attached to Jira ticket (screenshots, logs, dashboards, test reports)  </li> </ul>"},{"location":"developers/definition-of-done/#security","title":"Security","text":"<ul> <li>[ ] No new security vulnerabilities introduced  </li> <li>[ ] Dependencies are up to date (checked against vulnerability databases)  </li> </ul>"},{"location":"developers/definition-of-done/#deployment","title":"Deployment","text":"<ul> <li>[ ] Code successfully deploys to the test environment  </li> <li>[ ] Monitoring/alerting updated if needed  </li> </ul>"},{"location":"developers/development-process/","title":"Development Process","text":"<p>These are the preliminary development processes for developers and QAs. These processes are subject to continuous changes so it's advice to frequently review it for changes.</p>"},{"location":"developers/development-process/#developer-development-process","title":"Developer Development Process","text":"<ol> <li>Pick up ticket (3 amigos; optional)</li> <li>Define branch.    <pre><code>Format:\n\ne.g.\n\nfeat/FAB-XXX/{title}\nbug/FAB-XXX/{title}\n</code></pre></li> <li>Run tests to make sure you know everything is working before you start.</li> <li>Implement the necessary changes</li> <li>Implement playwright tests and fix broken tests</li> <li>Commit changes<ol> <li>Message format:    <pre><code>FAB-XXX {message}\n\n{details}\n</code></pre></li> </ol> </li> <li>Create pull request </li> <li>When pull request has been approved and merged, create release tag and push to master</li> <li>Deploy the generated release to the test environment</li> <li>Move the ticket to the Jira <code>Test</code> column and inform test lead</li> <li>The Test Lead will then run manual tests to see if the acceptance criteria was met. </li> <li>Once the Test Lead has signed off, deploy the tagged release to <code>staging</code> environment</li> </ol>"},{"location":"developers/development-process/#qa-test-suite-development-process","title":"QA Test Suite Development Process","text":"<ol> <li>Define or Pick up ticket in Jira Test column<ol> <li>Subtask to fix related tests (Ideally the responsibility of the Devs).</li> <li>Define general test fix, load testing, etc. ticket(s).</li> </ol> </li> <li>Move Jira ticket the 'In Progress'.</li> <li>Define branch. Format:</li> <li>task/FAB-XXX/{title} (for test fixes, modifications, etc.)</li> <li>test/FAB-XXX/{title} (for running complex tests, e.g. performance, load, security, etc. testing)</li> <li>Implement the necessary changes</li> <li>Add test modifications</li> <li>Commit changes</li> <li>Message format: \"FAB-XXX {message}\"</li> <li>Create pull request</li> <li>Move Jira ticket the 'Ready for Review'.</li> <li>Pull request approved and merged, by at least a Dev, QA or Technical Architect</li> <li>Mark ticket as 'Done'. Pass or fail.</li> </ol>"},{"location":"developers/project-setup/","title":"Project Setup","text":"<p>TODO: Define the project setup, including running locally, which secrets you need, etc</p>"},{"location":"developers/release-process/","title":"Release Process","text":"<p>This document outlines the process for deploying the application to the Test and Production environments.</p>"},{"location":"developers/release-process/#automated-deployments-to-test","title":"Automated Deployments to Test","text":"<p>When a pull request is merged into the <code>main</code> branch, the following actions are automatically triggered:</p> <ol> <li>New Tag Creation: The workflow finds the most recent tag (e.g., <code>v1.2.3</code>), increments it (to <code>v1.2.4</code>), and applies it to the merge commit.</li> <li>Deployment to Test: The newly tagged version is automatically deployed to the Test environment.</li> <li>Contentful Migrations: Any new Contentful migrations are also deployed to the Test environment.</li> </ol> <p>This process ensures that the Test environment always reflects the latest version of the <code>main</code> branch.</p>"},{"location":"developers/release-process/#deployments-to-environments","title":"Deployments to environments","text":"<p>Deployments to the Production environment are manual. The primary method is by creating a new release in GitHub.</p>"},{"location":"developers/release-process/#1-create-a-github-release-primary-method","title":"1. Create a GitHub Release (Primary Method)","text":"<p>This is the standard way to deploy a version that has been fully validated in the Test environment.</p> <ol> <li>Choose a Version: Identify the tag you want to release to production (e.g., <code>v1.2.4</code>).</li> <li>Create a New Release:<ul> <li>Navigate to the Releases page in the GitHub repository.</li> <li>Click Draft a new release.</li> <li>Select the tag you want to deploy from the Choose a tag dropdown.</li> <li>Add a title and description for the release notes.</li> <li>Click Publish release.</li> </ul> </li> <li>Automatic Deployment: Publishing the release automatically triggers the deployment workflow to the Production environment.</li> </ol>"},{"location":"developers/release-process/#2-manual-workflow-dispatch-if-you-just-want-to-deploy-latest-version-of-main-alternative-method","title":"2. Manual Workflow Dispatch - if you just want to deploy latest version of Main (Alternative Method)","text":"<p>You can also trigger a deployment manually without creating a formal release. This is useful for hotfixes or special circumstances.</p> <ol> <li>Navigate to the Actions tab in the GitHub repository.</li> <li>In the left sidebar, find and click on the Deploy - Environment workflow.</li> <li>Click the Run workflow dropdown button, which appears on the right side of the page.</li> <li>Select the branch you want to run the Workflow from or select the specific tag version (e.g., <code>v1.2.5</code>), the environment you want to deploy and if you want to Clear Cache. </li> <li>Click the green Run workflow button to start the deployment.</li> </ol>"},{"location":"testing/TestPlan/","title":"FEAT Project \u2013 QA Test Plan","text":""},{"location":"testing/TestPlan/#document-history","title":"Document History","text":"Version Date Author Reviewer(s) Approver Description of Changes 1.0 11/09/2025 Varsha Krishnamurthy 1. Stuart Duncan2. Clare Arolker3. Anita Holcroft (DfE) Initial draft of the test plan"},{"location":"testing/TestPlan/#1-introduction","title":"1. Introduction","text":"<p>The Find Education and Training (FEAT) platform consolidates all government-funded education and training opportunities into a single, unified search service. It integrates datasets from multiple sources (NCS, Apprenticeships, and Discover Uni), enriches them with AI embeddings, and exposes them through a user-facing website and API.</p>"},{"location":"testing/TestPlan/#technology-stack","title":"Technology Stack","text":"<ul> <li>Azure Infrastructure: Front Door, Blob, Bastion</li> <li>.NET 9 Services: API + ingestion pipeline</li> <li>Azure AI Search: Vector embeddings enabling hybrid semantic + keyword search</li> <li>Azure Cache: Microsoft Hybrid Cache \u2014 in-memory L1 cache + SQL Server L2 cache for performance and resilience</li> <li>UI Layer: DfE / Gov.UK Design System</li> </ul>"},{"location":"testing/TestPlan/#platform-aims","title":"Platform Aims","text":"<ul> <li>Empower young people and adults to explore post-16 education and training options.</li> <li>Support inclusivity for users with barriers (language, accessibility needs, dyslexia).</li> <li>Enable intermediaries (parents, teachers, advisers) to discover accurate opportunities.</li> <li>Ensure transparency on the role of AI in search results.</li> <li>Comply with accessibility standards (Gov.UK and WCAG 2.2 AA).</li> </ul>"},{"location":"testing/TestPlan/#document-purpose","title":"Document Purpose","text":"<p>This test plan defines the quality assurance strategy for FEAT. It covers scope, objectives, test approach, environments, risks, deliverables, defect management, and best practices to ensure FEAT is delivered as a reliable, performant, secure, and user-centric service.</p>"},{"location":"testing/TestPlan/#2-testing-objectives","title":"2. Testing Objectives","text":"<p>The primary objective of testing is to validate that the FEAT platform meets functional, non-functional, and compliance requirements while delivering a high-quality user experience.</p>"},{"location":"testing/TestPlan/#core-objectives","title":"Core Objectives","text":""},{"location":"testing/TestPlan/#functional-validation","title":"Functional Validation","text":"<ul> <li>Confirm correctness of website, API, and ingestion pipeline features.</li> <li>Ensure seamless integration between components (API \u2194 DB \u2194 Search \u2194 Cache).</li> </ul>"},{"location":"testing/TestPlan/#data-quality-relevance","title":"Data Quality &amp; Relevance","text":"<ul> <li>Validate accuracy, completeness, deduplication, and consistency of datasets.</li> <li>Test AI embeddings for semantic relevance, typo tolerance, and edge cases.</li> </ul>"},{"location":"testing/TestPlan/#non-functional-qualities","title":"Non-Functional Qualities","text":"<ul> <li>Verify performance, scalability, and resilience under peak load.</li> <li>Confirm security posture against OWASP Top 10 vulnerabilities.</li> <li>Validate disaster recovery readiness (RTO/RPO, failover, backups).</li> </ul>"},{"location":"testing/TestPlan/#compliance-accessibility","title":"Compliance &amp; Accessibility","text":"<ul> <li>Ensure compliance with Gov.UK design standards.</li> <li>Validate WCAG 2.2 AA accessibility, including screen readers and keyboard-only navigation.</li> <li>Confirm AI disclosure and transparency requirements.</li> </ul>"},{"location":"testing/TestPlan/#operational-readiness","title":"Operational Readiness","text":"<ul> <li>For private beta, focus on ensuring FEAT is stable, testable, and observable.</li> <li>Broader service transition processes apply later at public beta once integrated into wider Skills journey (e.g., NCS or Skills for Careers).</li> </ul>"},{"location":"testing/TestPlan/#3-testing-scope","title":"3. Testing Scope","text":"<p>Defines boundaries of testing: what is in scope and out of scope.</p>"},{"location":"testing/TestPlan/#31-in-scope","title":"3.1 In Scope","text":""},{"location":"testing/TestPlan/#functional-testing","title":"Functional Testing","text":"<ul> <li>Website: search, navigation, filters, AI disclosure, accessibility features</li> <li>API: query handling, endpoints, caching, and error handling</li> <li>Ingestion Pipeline: data ingestion, transformation, and embeddings generation</li> </ul>"},{"location":"testing/TestPlan/#integration-testing","title":"Integration Testing","text":"<ul> <li>End-to-end data flow: Ingestion \u2192 Database \u2192 Search Index \u2192 API \u2192 Website</li> <li>Cache synchronisation and expiry validation</li> <li>API contract validation (including consumer-driven contract testing)</li> </ul>"},{"location":"testing/TestPlan/#data-quality-relevance-testing","title":"Data Quality &amp; Relevance Testing","text":"<ul> <li>Schema validation (PK/FK integrity, mandatory fields)</li> <li>Deduplication and consistency across datasets</li> <li>Semantic similarity and AI embeddings validation</li> <li>Validation of data completeness and edge cases</li> </ul>"},{"location":"testing/TestPlan/#non-functional-testing","title":"Non-Functional Testing","text":"<ul> <li>Performance &amp; Scalability: Load, stress, endurance testing for API and frontend</li> <li>Accessibility: Automated + manual WCAG 2.2 AA compliance</li> <li>Security: OWASP Top 10, penetration testing, input sanitisation</li> <li>Disaster Recovery (DR): Failover testing, backup/restore validation</li> </ul>"},{"location":"testing/TestPlan/#cross-platform-device-testing","title":"Cross-Platform &amp; Device Testing","text":"<ul> <li>Browser coverage (Chromium, Edge, Safari, Firefox)</li> <li>Mobile-first validation across iOS and Android devices</li> </ul>"},{"location":"testing/TestPlan/#32-out-of-scope","title":"3.2 Out of Scope","text":"<ul> <li>Third-party provider systems (e.g., NCS, Apprenticeship Service, HESA) infrastructure \u2013 outside DfE control</li> <li>AI model training or fine-tuning \u2013 focus is on integration &amp; relevance validation, not model development</li> </ul>"},{"location":"testing/TestPlan/#4-test-approach","title":"4. Test Approach","text":"<p>A multi-layered strategy combining functional, non-functional, and compliance testing. Automated testing where feasible, complemented by exploratory/manual QA for usability and accessibility.</p>"},{"location":"testing/TestPlan/#testing-methodologies","title":"Testing Methodologies","text":""},{"location":"testing/TestPlan/#manual-testing","title":"Manual Testing","text":"<ul> <li>Exploratory, smoke, sanity, and accessibility</li> <li>Testing of Data model and Ingestion service</li> <li>Usability checks aligned with GovUK Design System</li> </ul>"},{"location":"testing/TestPlan/#automated-testing","title":"Automated Testing","text":"<ul> <li>UI, API, regression, and E2E flows</li> <li>CI/CD integrated, triggered on deployments</li> </ul>"},{"location":"testing/TestPlan/#tools","title":"Tools","text":"<ul> <li>Functional/Automation: Playwright + .NET, Postman, K6</li> <li>Performance: JMeter, Azure Load Testing or K6</li> <li>Accessibility: Lighthouse, Pa11y, axe-core, WAVE</li> <li>Security: OWASP ZAP, SonarQube</li> <li>CI/CD: GitHub Actions</li> </ul>"},{"location":"testing/TestPlan/#testing-phases","title":"Testing Phases","text":"<ol> <li>Unit Testing (Dev-led) \u2013 Core functions, APIs, ingestion pipeline; run in CI pipeline</li> <li>Integration Testing (Dev/QA) \u2013 Validate API contracts, cache sync, ingestion\u2192DB\u2192Search flows; Pact tests</li> <li>Data Quality &amp; Relevance Testing (QA-led) \u2013 Schema validation, deduplication, AI embeddings relevance, edge cases</li> <li>End-to-End (QA-led) \u2013 Simulate real journeys, browser/device coverage</li> <li>Performance &amp; Scalability (QA-led) \u2013 Simulate peak traffic, stress ingestion pipeline, resilience checks</li> <li>Accessibility (QA-led) \u2013 Automated + manual testing with assistive tech</li> <li>Security (Dev/QA) \u2013 Input sanitisation, auth/role checks, OWASP Top 10</li> <li>Disaster Recovery (Dev/QA) \u2013 Validate RTO/RPO, test cache/DB failover, Blob recovery</li> </ol>"},{"location":"testing/TestPlan/#5-test-environments","title":"5. Test Environments","text":""},{"location":"testing/TestPlan/#51-environment-setup","title":"5.1 Environment Setup","text":"Environment Purpose Characteristics Dev Development Test Functional + integration Stable builds, anonymised datasets, mocks for 3rd party APIs Staging E2E + performance + security Mirrors production, realistic data, AI embeddings applied Production Live service Limited to smoke tests + monitoring"},{"location":"testing/TestPlan/#52-test-data","title":"5.2 Test Data","text":"<ul> <li>Synthetic Test Data: Generated sample courses, apprenticeships, and providers</li> <li>Realistic Production-like Data: Anonymised datasets from NCS / Discover Uni</li> <li>Negative Test Data: Corrupted, missing, malformed records to test ingestion resilience</li> <li>AI Edge Cases: Queries with synonyms, ambiguous words, misspellings</li> </ul>"},{"location":"testing/TestPlan/#6-entry-exit-criteria","title":"6. Entry &amp; Exit Criteria","text":""},{"location":"testing/TestPlan/#entry-criteria","title":"Entry Criteria","text":"<ul> <li>Approved requirements/user stories</li> <li>Stable build deployed to Testing/Staging</li> <li>Test data available in required format</li> </ul>"},{"location":"testing/TestPlan/#exit-criteria","title":"Exit Criteria","text":"<ul> <li>100%+ test case execution completed</li> <li>No open Priority 1 and 2, Severity 1 or 2 defects</li> <li>Performance benchmarks met (response time &lt; 2s for 95% queries \u2013 TBC)</li> <li>Accessibility compliance confirmed</li> </ul>"},{"location":"testing/TestPlan/#7-risks-mitigations","title":"7. Risks &amp; Mitigations","text":"Risk Impact Mitigation Incomplete/dirty source data Poor search results Data validation &amp; cleansing rules, anomaly detection tests AI model returns irrelevant results User frustration, lack of trust Relevance tests, human-in-loop review for edge cases Cache misconfiguration Stale/incorrect results Automated cache expiry tests Infrastructure scaling issues Site downtime under load Load &amp; stress testing in PERF environment Security vulnerabilities Data breach Azure Security Center monitoring"},{"location":"testing/TestPlan/#8-test-deliverables","title":"8. Test Deliverables","text":"<ul> <li>Test Strategy &amp; Detailed Test Plan</li> <li>Automated Test Suites: UI (Playwright with .NET), API (Postman, Playwright/K6)</li> <li>Manual Test cases covering Data Quality</li> <li>Test Execution Reports</li> <li>Accessibility audit reports</li> <li>Security &amp; penetration test reports</li> <li>Performance benchmark reports</li> <li>Defect Reports (Jira)</li> <li>Final Test Closure Report</li> </ul>"},{"location":"testing/TestPlan/#9-governance-reporting","title":"9. Governance &amp; Reporting","text":"<ul> <li>Test Management Tool: Jira, Git</li> <li>Defect Tracking: Jira with agreed severity/priority</li> <li>Reporting Cadence: Daily progress in standups, weekly QA dashboard, Go/No-Go quality gate before release</li> </ul>"},{"location":"testing/TestPlan/#10-defect-management-source-of-truth-and-qa-best-practices","title":"10. Defect Management, Source of Truth, and QA Best Practices","text":""},{"location":"testing/TestPlan/#101-defect-lifecycle","title":"10.1 Defect Lifecycle","text":"Stage Description Responsibility New / Logged Reported in tool with steps, env, severity, screenshots/logs QA Tester Triaged / Confirmed QA Lead/Product Owner reviews, prioritizes, filters duplicates QA Lead/PO Assigned Assigned to responsible developer/team Development Team In Progress Developer investigates/fixes, QA may clarify Developer Fixed / Ready for Retest Fix deployed to test/staging, QA prepares for retest Developer / QA Retest QA validates fix and regression QA Tester Closed Defect passes retest, meets acceptance criteria QA Lead Reopened If defect persists, reopened and reassigned QA Tester <p>Severity Levels</p> <ul> <li>S1 (Critical): Blocking production or core functionality</li> <li>S2 (High): Major feature broken, workaround exists</li> <li>S3 (Medium): Minor feature or UI issue</li> <li>S4 (Low / Cosmetic): Minor visual/textual issues</li> </ul>"},{"location":"testing/TestPlan/#102-source-of-truth","title":"10.2 Source of Truth","text":"<ul> <li>UI: Approved prototype</li> <li>Functional: User stories and acceptance criteria</li> <li>Test Cases &amp; Automation Scripts: GitHub version-controlled repo</li> <li>Defects / Issues: Tracked in Jira, linked to stories/test cases</li> <li>Test Execution Reports &amp; Metrics: Centralized QA repository</li> <li>Communication &amp; Reporting: Weekly dashboard and standups</li> </ul>"},{"location":"testing/TestPlan/#103-qa-best-practices","title":"10.3 QA Best Practices","text":"<ul> <li>Traceability: Link test cases to requirements; defects to test cases</li> <li>Shift-Left Testing: Test early to detect defects sooner</li> <li>Automation First: Regression, critical workflows, API tests</li> <li>Exploratory Testing: Complement automation for usability, accessibility, edge cases</li> <li>Peer Reviews: Review test cases, scripts, defect logs</li> <li>Consistent Defect Logging: Include env, reproduction steps, screenshots, logs, test data</li> <li>Continuous Improvement: Lessons learned after each release</li> <li>Metrics &amp; Reporting: Track defect density, age, automation coverage, performance benchmarks, accessibility scores</li> <li>Environment Hygiene: Refresh and stabilize test environments to mirror production</li> <li>Compliance Checks: GDPR, accessibility, AI transparency, security included in QA processes  </li> </ul>"}]}